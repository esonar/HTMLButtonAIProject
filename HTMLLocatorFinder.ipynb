{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSVobPa836Pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3daf8543-6d5b-48ed-f0c2-661839eaa6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 204ms/step - accuracy: 0.4640 - loss: 7.2730 - val_accuracy: 0.7417 - val_loss: 5.7432 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - accuracy: 0.7603 - loss: 5.3452 - val_accuracy: 0.7598 - val_loss: 4.2713 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.8067 - loss: 4.0006 - val_accuracy: 0.7628 - val_loss: 3.2524 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.8599 - loss: 3.0619 - val_accuracy: 0.8649 - val_loss: 2.5611 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8897 - loss: 2.4393 - val_accuracy: 0.9189 - val_loss: 2.1028 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9412 - loss: 2.0023 - val_accuracy: 0.9129 - val_loss: 1.7778 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9566 - loss: 1.6993 - val_accuracy: 0.9489 - val_loss: 1.5495 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.9717 - loss: 1.4872 - val_accuracy: 0.9580 - val_loss: 1.3731 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.9804 - loss: 1.3334 - val_accuracy: 0.9700 - val_loss: 1.2388 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.9818 - loss: 1.1996 - val_accuracy: 0.9610 - val_loss: 1.1381 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9827 - loss: 1.0818 - val_accuracy: 0.9670 - val_loss: 1.0398 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9857 - loss: 0.9952 - val_accuracy: 0.9730 - val_loss: 0.9519 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.9871 - loss: 0.9143 - val_accuracy: 0.9730 - val_loss: 0.8798 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.9902 - loss: 0.8428 - val_accuracy: 0.9820 - val_loss: 0.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.9915 - loss: 0.7802 - val_accuracy: 0.9790 - val_loss: 0.7599 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.9966 - loss: 0.7168 - val_accuracy: 0.9700 - val_loss: 0.7115 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9960 - loss: 0.6744 - val_accuracy: 0.9820 - val_loss: 0.6578 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9972 - loss: 0.6283 - val_accuracy: 0.9820 - val_loss: 0.6162 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - accuracy: 0.9996 - loss: 0.5781 - val_accuracy: 0.9850 - val_loss: 0.5789 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9981 - loss: 0.5409 - val_accuracy: 0.9820 - val_loss: 0.5437 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.9991 - loss: 0.5054 - val_accuracy: 0.9850 - val_loss: 0.5178 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9990 - loss: 0.4713 - val_accuracy: 0.9760 - val_loss: 0.4905 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9932 - loss: 0.4492 - val_accuracy: 0.9820 - val_loss: 0.4605 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.9987 - loss: 0.4218 - val_accuracy: 0.9850 - val_loss: 0.4322 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9986 - loss: 0.3959 - val_accuracy: 0.9850 - val_loss: 0.4058 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.9982 - loss: 0.3698 - val_accuracy: 0.9850 - val_loss: 0.3887 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.9994 - loss: 0.3489 - val_accuracy: 0.9880 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9994 - loss: 0.3344 - val_accuracy: 0.9880 - val_loss: 0.3467 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.9975 - loss: 0.3115 - val_accuracy: 0.9820 - val_loss: 0.3357 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.9989 - loss: 0.2946 - val_accuracy: 0.9820 - val_loss: 0.3222 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9993 - loss: 0.2815 - val_accuracy: 0.9880 - val_loss: 0.3050 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.9991 - loss: 0.2678 - val_accuracy: 0.9880 - val_loss: 0.2879 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.9965 - loss: 0.2575 - val_accuracy: 0.9880 - val_loss: 0.2808 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.2399 - val_accuracy: 0.9730 - val_loss: 0.2781 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9999 - loss: 0.2320 - val_accuracy: 0.9880 - val_loss: 0.2547 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9994 - loss: 0.2181 - val_accuracy: 0.9820 - val_loss: 0.2505 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9968 - loss: 0.2160 - val_accuracy: 0.9850 - val_loss: 0.2411 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - accuracy: 0.9979 - loss: 0.2074 - val_accuracy: 0.9880 - val_loss: 0.2347 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9998 - loss: 0.2006 - val_accuracy: 0.9850 - val_loss: 0.2243 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9996 - loss: 0.1921 - val_accuracy: 0.9850 - val_loss: 0.2194 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - accuracy: 0.9991 - loss: 0.1802 - val_accuracy: 0.9850 - val_loss: 0.2249 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.9941 - loss: 0.1820 - val_accuracy: 0.9850 - val_loss: 0.2129 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.9998 - loss: 0.1647 - val_accuracy: 0.9880 - val_loss: 0.1985 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.9967 - loss: 0.1673 - val_accuracy: 0.9850 - val_loss: 0.2039 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.1589 - val_accuracy: 0.9880 - val_loss: 0.1930 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9983 - loss: 0.1517 - val_accuracy: 0.9850 - val_loss: 0.1875 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.1536 - val_accuracy: 0.9880 - val_loss: 0.1817 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.1439 - val_accuracy: 0.9850 - val_loss: 0.1802 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.9992 - loss: 0.1399 - val_accuracy: 0.9880 - val_loss: 0.1761 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.1371 - val_accuracy: 0.9880 - val_loss: 0.1746 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.1342 - val_accuracy: 0.9850 - val_loss: 0.1701 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.1274 - val_accuracy: 0.9850 - val_loss: 0.1668 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.9992 - loss: 0.1277 - val_accuracy: 0.9820 - val_loss: 0.1877 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.9990 - loss: 0.1300 - val_accuracy: 0.9820 - val_loss: 0.1674 - learning_rate: 1.0000e-04\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9891 - loss: 0.1532\n",
            "Validation Loss: 0.16675850749015808, Validation Accuracy: 0.9849849939346313\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Embedding, Multiply, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load data from CSV file\n",
        "csv_file_path = '/content/data_trial_090924.csv'  # Adjust the file path as needed\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract labels and HTML codes from the CSV\n",
        "# **Assuming your CSV has columns 'label' and 'html_code'**\n",
        "labels = data['label'].tolist()\n",
        "html_codes = data['data'].tolist()\n",
        "\n",
        "# If your CSV does not have headers, you can use:\n",
        "# labels = data.iloc[:, 0].tolist()  # First column contains labels\n",
        "# html_codes = data.iloc[:, 1].tolist()  # Second column contains HTML codes\n",
        "\n",
        "command = \"click()\"\n",
        "\n",
        "# Compute class weights after labels are defined\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = dict(enumerate(class_weights))  # Convert to a dictionary for Keras\n",
        "\n",
        "# Function to preprocess HTML with command\n",
        "def preprocess_html_with_command(html_codes, command):\n",
        "    input_ids_batch = []\n",
        "    attention_mask_batch = []\n",
        "\n",
        "    for html_code in html_codes:\n",
        "        # Parse HTML and extract elements\n",
        "        soup = BeautifulSoup(html_code, 'html.parser')\n",
        "        elements = []\n",
        "        for tag in soup.find_all(True):\n",
        "            tag_name = tag.name\n",
        "            attrs = tag.attrs\n",
        "            text = tag.get_text(strip=True)\n",
        "\n",
        "            elements.append(tag_name)\n",
        "            for attr, value in attrs.items():\n",
        "                elements.append(f'{attr}=\"{value}\"')\n",
        "            if text:\n",
        "                elements.append(text)\n",
        "\n",
        "        # Append the command\n",
        "        elements.append(command)\n",
        "\n",
        "        # Convert elements to string and tokenize\n",
        "        processed_html = \" \".join(elements)\n",
        "        tokens = tokenizer.tokenize(processed_html)\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "        # Convert tokens to IDs\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad or truncate input_ids and attention_mask\n",
        "        max_length = 100                #max_length = 500 #max_length = 100 optimized\n",
        "        if len(input_ids) > max_length:\n",
        "            input_ids = input_ids[:max_length]\n",
        "            attention_mask = attention_mask[:max_length]\n",
        "        else:\n",
        "            padding_length = max_length - len(input_ids)\n",
        "            input_ids += [0] * padding_length\n",
        "            attention_mask += [0] * padding_length\n",
        "\n",
        "        input_ids_batch.append(input_ids)\n",
        "        attention_mask_batch.append(attention_mask)\n",
        "\n",
        "    return np.array(input_ids_batch), np.array(attention_mask_batch)\n",
        "\n",
        "# Preprocess the batch of HTML codes with the command\n",
        "input_ids_batch, attention_mask_batch = preprocess_html_with_command(html_codes, command)\n",
        "\n",
        "# Map unique labels to integers\n",
        "unique_labels = sorted(set(labels))\n",
        "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "label_ids = [label_map[label] for label in labels]\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = len(label_map)\n",
        "y_one_hot = tf.keras.utils.to_categorical(label_ids, num_classes=num_classes)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_ids, X_val_ids, X_train_mask, X_val_mask, y_train, y_val = train_test_split(\n",
        "    input_ids_batch, attention_mask_batch, y_one_hot, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define a custom layer to apply the attention mask\n",
        "class MaskedEmbedding(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskedEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedding, attention_mask = inputs\n",
        "        return Multiply()([embedding, tf.cast(tf.expand_dims(attention_mask, -1), dtype=tf.float32)])\n",
        "#--------------------------------------\n",
        "# Define the model with regularization\n",
        "def build_regularized_model(max_length, num_classes):\n",
        "    input_ids = Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    embedding = Embedding(input_dim=30522, output_dim=128, name='embedding')(input_ids)\n",
        "    masked_output = MaskedEmbedding(name='masked_embedding')([embedding, attention_mask])\n",
        "\n",
        "    flatten = Flatten()(masked_output)\n",
        "    dense1 = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(flatten)\n",
        "    dropout1 = Dropout(0.5)(dense1)\n",
        "    dense2 = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(dropout1)\n",
        "    dropout2 = Dropout(0.5)(dense2)\n",
        "    output = Dense(num_classes, activation='softmax')(dropout2)\n",
        "\n",
        "    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), #learning_rate = 0.0001\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #eski burası\n",
        "\n",
        "# Implement early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.000001)\n",
        "\n",
        "# Build and train the model with regularization\n",
        "model = build_regularized_model(max_length=100, num_classes=num_classes) #max_length = 500 #max_length = 100 optimized\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask],\n",
        "    y_train,\n",
        "    validation_data=([X_val_ids, X_val_mask], y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "loss, accuracy = model.evaluate([X_val_ids, X_val_mask], y_val)\n",
        "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict etmesi için olan kod\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#new_html_code = \"\"\"<button type=\"button\" class=\"btn btn-primary\" id=\"action-button\" name=\"submit-btn\">Click Me!</button>\"\"\"    # id örnek\n",
        "#new_html_code = \"\"\"<button type=\"button\" class=\"close-dialog-window\" data-dismiss=\"modal\" aria-label=\"Close\"><span aria-hidden=\"true\">×</span></button>\"\"\" #class örnek\n",
        "#new_html_code = \"\"\"<button class=\"back-to-home\" id=\"home-button\" aria-label=\"Go to Home\"><span class=\"home-icon\"></span></button>\"\"\" #id örnek\n",
        "new_html_code = \"\"\"<button class=\"confirm-btn\" name=\"confirm-data\">Confirm Data</button>\"\"\" # name örnek\n",
        "\n",
        "new_input_ids, new_attention_mask = preprocess_html_with_command([new_html_code], command)\n",
        "\n",
        "prediction = model.predict([new_input_ids, new_attention_mask])\n",
        "predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "# Map back the predicted class to the label\n",
        "idx_to_label = {idx: label for label, idx in label_map.items()}\n",
        "predicted_label = idx_to_label[predicted_class_index]\n",
        "\n",
        "print(f\"Predicted Class Index: {predicted_class_index}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "# For debugging: Check distribution of your labels\n",
        "print(\"Label Distribution:\", Counter(labels))\n",
        "\n",
        "# For debugging: Print label_map\n",
        "print(\"Label Map:\", label_map)\n",
        "\n",
        "#-------------------------------------------------\n",
        "\n",
        "# Parse the HTML using BeautifulSoup\n",
        "soup = BeautifulSoup(new_html_code, 'html.parser')\n",
        "\n",
        "# Extract values for id, name, and class attributes\n",
        "\n",
        "# Function to find the first element with a specific attribute\n",
        "def find_element_by_attribute(attribute):\n",
        "    elements_with_attr = soup.find_all(attrs={attribute: True})\n",
        "    if elements_with_attr:\n",
        "        return elements_with_attr[0][attribute]\n",
        "    return None\n",
        "\n",
        "# Extract the first id, name, and class attribute values from the HTML\n",
        "predicted_id_value = find_element_by_attribute(\"id\")\n",
        "predicted_name_value = find_element_by_attribute(\"name\")\n",
        "predicted_class_value = find_element_by_attribute(\"class\")\n",
        "\n",
        "#Bulduğumuz değerleri birleştirme\n",
        "print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "if predicted_label==\"id\":\n",
        "    print(f'Predicted ID value: {predicted_id_value}')\n",
        "    print(f'Predicted locator: {predicted_label} = \"{predicted_id_value}\"') #bulduğu id'i printleme\n",
        "\n",
        "elif predicted_label==\"class\":\n",
        "    print(f'Predicted Class value: {predicted_class_value}')\n",
        "    print(f'Predicted locator: {predicted_label} = \"{predicted_class_value[0]}\"') #bulduğu class'ı printleme\n",
        "\n",
        "elif predicted_label==\"name\":\n",
        "    print(f'Predicted Name value: {predicted_name_value}')\n",
        "    print(f'Predicted locator: {predicted_label} = \"{predicted_name_value}\"') #bulduğu name'i printleme\n",
        "\n",
        "else:\n",
        "    print('No element with an attribute found.')"
      ],
      "metadata": {
        "id": "YKYPXc_94SIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a6c0ae-dc94-47bb-96f8-a45e8a86dc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted Class Index: 2\n",
            "Predicted Label: name\n",
            "Label Distribution: Counter({'class': 555, 'id': 554, 'name': 554})\n",
            "Label Map: {'class': 0, 'id': 1, 'name': 2}\n",
            "Predicted Label: name\n",
            "Predicted Name value: confirm-data\n",
            "Predicted locator: name = \"confirm-data\"\n"
          ]
        }
      ]
    }
  ]
}